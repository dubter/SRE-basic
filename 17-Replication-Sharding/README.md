# Домашнее задание №17 "Репликация и шардирование"


## PostgreSQL Replication Project

Этот проект демонстрирует настройку репликации данных между мастер- и реплика-узлами PostgreSQL с использованием Docker. В проекте есть проблемы с репликацией, которые необходимо решить.
Инструкции по сборке и запуску
1) Убедитесь, что у вас установлен Docker и Docker Compose.
2) Перейдите в корневую директорию проекта:
```
   cd postgres-replication-project
```
3) Соберите и запустите контейнеры:
```
   docker-compose up --build -d
``` 
4) Зайдите в контейнер master и заполните базу данных
```
   docker exec -it postgres-master psql -U postgres
   INSERT INTO test_data (value) SELECT 'test' FROM generate_series(1, 10000000);
```   
5) Подключитесь к реплике и проверьте статус репликации
```
   docker exec -it postgres-replica1 psql -U postgres
   SELECT * FROM pg_stat_replication;
```   
6) Вы увидите, что реплика отстает (поле `pg_stat_replication` будет пустым или с высоким lag).
Проблема с репликацией
В текущей конфигурации могут возникнуть проблемы с репликацией данных между мастер- и реплика-узлами. Необходимо проверить настройки подключения, параметры репликации и убедиться, что все необходимые SQL-скрипты для инициализации базы данных выполнены корректно.

*Найдите несколько способов устранения отставания репликации*

> [!NOTE]
> **Критерии оценки**:
> * 1 способ - 5 баллов
> * 2 способа - 8 баллов
> * 3 способа - 10 баллов

## Решение

### Оптимизация лага репликации PostgreSQL

### Проблема

В исходной конфигурации PostgreSQL наблюдалось заметное отставание репликации между мастер-сервером и репликами. Это могло приводить к несогласованности данных, проблемам при чтении с реплик и потенциальным конфликтам при выполнении запросов.

### Методология

Для измерения лага использовался встроенный механизм PostgreSQL — запрос к системной таблице `pg_stat_replication`. Оценивались три ключевых показателя:

* write_lag — задержка записи WAL-логов
* flush_lag — задержка сброса WAL-логов на диск
* replay_lag — задержка применения изменений на реплике

### Результаты до и после оптимизации

| Метрика     | До оптимизации | После оптимизации | Улучшение  |
|-------------|----------------|-------------------|------------|
| Write lag   | 0.20-0.21 мс   | 0.16-0.19 мс      | ~ 10%      |
| Flush lag   | 3.2-5.3 мс     | 0.40 мс           | ~ 92%      |
| Replay lag  | 8.9-9.8 мс     | 0.42-0.45 мс      | ~ 95%      |

### Способы оптимизации

1) Изменения в конфигурации мастера

```
# Добавлено в postgresql.conf на мастере
wal_compression = on              # Сжатие WAL логов для оптимизации I/O
max_wal_size = 1GB                # Увеличение размера WAL для снижения частоты чекпоинтов
checkpoint_timeout = 15min        # Более редкие чекпоинты
checkpoint_completion_target = 0.9 # Растягивание записи чекпоинта для равномерной нагрузки
commit_delay = 0                  # Минимальная задержка фиксации
commit_siblings = 5               # Группировка транзакций
```

**Эффект:** Эти изменения оптимизируют работу с WAL-логами, снижая нагрузку на диск и делая создание чекпоинтов более эффективным. Сжатие WAL логов (wal_compression) уменьшает объем передаваемых по сети данных, что сокращает задержку репликации.

2) Изменения в конфигурации реплики

```
# Добавлено в postgresql.conf на репликах
hot_standby_feedback = on        # Обратная связь с мастером для предотвращения конфликтов
max_standby_archive_delay = 300s # Больше времени для запросов на реплике
max_standby_streaming_delay = 30s # Увеличенная задержка для запросов при получении данных
```

**Эффект:** Включение hot_standby_feedback значительно уменьшает количество конфликтов между мастером и репликой, что позволяет репликам быстрее применять изменения. Параметры max_standby_*_delay предотвращают отмену долгих запросов на репликах из-за конфликтов с WAL-записями.

3) Оптимизация ресурсов в docker-compose

```
# Изменения в docker-compose.yml
postgres-master:
  deploy:
    resources:
      limits:
        cpus: '2.0'       # Было неопределено
        memory: 1G        # Было неопределено
      reservations:
        cpus: '1.0'
        memory: 512M

postgres-replica1:
  deploy:
    resources:
      limits:
        cpus: '1.0'       # Было 0.5
        memory: 512M      # Было 256M

networks:
  postgres-network:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 9000  # Оптимизация сети
```

**Эффект:** Выделение большего количества CPU и памяти для репликационных процессов обеспечивает более быструю обработку WAL-логов. Увеличенный MTU в сетевых настройках позволяет передавать большие пакеты данных за одну операцию, что снижает накладные расходы сети.

## Выводы
Самый значительный эффект дало включение hot_standby_feedback на репликах, что видно по драматическому снижению replay_lag (на 95%). Оптимизация ресурсов контейнеров была второй по значимости, особенно для flush_lag, что указывает на улучшенную производительность I/O. Комбинация всех трех подходов позволила достичь почти синхронной репликации с лагом менее 0.5 мс, что приближается к идеальным показателям для большинства производственных систем.

Следует отметить, что хотя исходный лаг (8-10 мс) уже был довольно хорошим, проведенная оптимизация позволила достичь практически идеальной репликации в режиме реального времени.



